## 1. 进程与线程

### 1.1 进程与线程的区别

进程：**进程是一个正在执行程序的实例，拥有自己的程序计数器和内部状态，是系统进行资源分配和调度的一个独立单位**（具有动态、并发、独立、异步的特性，以及就绪、执行、阻塞3种状态，资源拥有单位等属性）；引入进程是为了使多个程序可以并发的执行，以提高系统的资源利用率和吞吐量。

线程：是比进程更小的可独立运行的基本单位，可以看做是**轻量级的进程**（具有轻型实体，独立调度分派单位，可并发执行，**共享进程资源**等属性）；引入目的是为了减少程序在并发执行过程中的开销，使OS的并发效率更高。

两者的对比：

1. 调度方面：在引入线程的OS中，线程是独立的调度和分派单位，而进程作为资源的拥有单位(相当于把未引入线程的传统OS中的进程的两个属性分开了)。**由于线程不拥有资源，因此可以显著的提高并发度以及减少切换开销**。
2. 并发性：引入了线程的OS中，进程间可以并发，而且一个进程内部的多个线程之间也是可以并发的，这就使OS具有更好的并发性，有效的提高了系统资源利用率和吞吐量。
3. 拥有资源：处于安全和方便管理的因素，一个进程往往会**独占一些资源，如地址空间、全局变量、打开的文件、子进程、信号和账户信息**等；而为了处理各自的任务，线程也会独占一些资源，如**栈、寄存器、程序计数器**和状态等。
4. 系统开销：创建或者撤销进程的时候，系统要为之创建或回收PCB，系统资源等，切换时也需要保存和恢复CPU环境。而线程的切换只需要保存和恢复少量的寄存器，不涉及存储器管理方面的工作，所以开销较小。此外，**统一进程中的多个线程由于共享地址空间**，所以通信同步等都比较方便。

**进程中线程共享的资源：地址空间、全局变量、打开文件、子进程、信号与信号处理程序、账户信息。**

**进程中线程独占的资源：程序计数器、寄存器、堆栈、状态。**

### 1.2 进程的实现与状态

为实现进程模型，操作系统维护着一个结构体数组，即进程表（process table）。每个进程占用一个进程表项，该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、优先级、信号、内存分配状况（正文段指针、数据段指针、堆栈段指针）、所打开文件的状态，以及其他在进程由运行态转换到阻塞态时必须保存的信息。从而保证该进程随后能再次启动，就像从未被中断过一样。

进程拥有三种状态：

1. 运行态，此时进程正占用着CPU；
2. 就绪态，进程处于可运行状态，但因为其他进程正在运行而暂时停止；
3. 阻塞态，除非外部事件发生，否则进程不能运行。

进程的三种状态之间有四种可能的转换关系，如图所示：

![image-20201028001025332](https://markdown-wq-1302077921.cos.ap-guangzhou.myqcloud.com/PicGoimage-20201028001025332.png)

当一个进程从管道或设备文件读数据（如终端）读数据时，如果没有有效的输入存在，则进程会被自动阻塞。当进程收到有效输入时，则会从阻塞态转换到就绪态。如果此时没有其他进程运行，则立即从就绪态转换到运行态。

### 1.3 线程的实现方式

**在用户空间中实现线程**
用户级线程指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，应用进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。不需要用户态/核心态切换，速度快，操作系统内核不知道多线程的存在，因此一个线程阻塞将使得整个进程（包括它的所有线程）阻塞。由于这里的处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少。

**在内核中实现线程**
内核级线程由操作系统内核创建和撤销。内核维护进程及线程的上下文信息以及线程切换。一个内核线程由于I/O操作而阻塞，不会影响其它线程的运行。

由于在内核中创建或撤销线程的代价比较大，某些系统采取“环保”的处理方式，回收线程。当某个线程被撤销时，就把它标记为不可运行的，但是其内核数据结构没有受到影响。后面在必须创建一个新线程时，就重新启用某个旧线程，从而节省开销。

**在用户空间中实现线程的优势**

- 可以在不支持线程的操作系统中实现。
- 创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。
- 允许每个进程定制自己的调度算法，线程管理比较灵活。
- 线程能够利用的表空间和堆栈空间比内核级线程多。

**在用户空间中实现线程的缺点**

- 同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。
- 页面失效也会导致整个进程都会被挂起。

内核线程的优缺点刚好跟用户线程相反。实际上，**操作系统可以使用混合的方式来实现线程。**

### 1.4 线程同步原语

**竞争条件**：两个或多个线程读写某些共享数据，而最后的结果取决于线程运行的精确时序。为避免竞争条件，需要找到某种途径组织多个线程同时读写共享的数据。这里，我们把对共享数据（共享内存）进行访问的程序片段称之为**临界区**，只要我们能够使两个线程不可能同时处于临界区，就能够避免竞争条件。

同步机制需要遵循的原则：

1. 空闲让进：当没有线程处于临界区的时候，应该许可其他线程进入临界区的申请。
2. 忙则等待：当前如果有线程处于临界区，如果有其他线程申请进入，则必须等待，保证对临界区的互斥访问。
3. 有限等待：对要求访问临界资源的线程，需要在有限时间内进入临界区，防止出现死等。
4. 让权等待：当线程无法进入临界区的时候，需要释放处理机，边陷入忙等。

线程同步的常用方法：**互斥锁，条件变量，信号量，屏障**。

**互斥锁**：同一时刻只允许一个线程进入临界区。互斥锁有两个基本操作，加锁和解锁。一个线程如果想要进入临界区，它首先需要尝试锁住相关的互斥量。如果互斥量没有加锁，那么这个线程可以立即进入，并对互斥量进行加锁以防止其他线程进入。如果互斥量已经被加锁，则调用线程被阻塞，直至该互斥量被解锁。

```C++
// 互斥锁的初始化
int pthread_mutex_init(pthread_mutex_t *restrict mutex,const pthread_mutexattr_t *restrict attr);
// 销毁互斥锁，释放其所占用的资源
int pthread_mutex_destroy(pthread_mutex_t *mutex);
// 加锁和解锁操作
// trylock加锁时，如果锁被占用，则返回EBUSY，而不是挂起等待
int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);
int pthread_mutex_trylock(pthread_mutex_t *mutex);
```

互斥锁的类型属性：

- `PTHREAD_MUTEX_TIMED_NP`：默认普通锁。当一个线程加锁以后，其余请求锁的线程将形成一个等待队列，并在解锁后按优先级获得锁。这种锁策略保证了资源分配的公平性。
- `PTHREAD_MUTEX_RECURSIVE_NP`：嵌套锁，允许同一个线程对同一个锁成功获得多次，并通过多次unlock解锁。如果是不同线程请求，则在加锁线程解锁时重新竞争。
- `PTHREAD_MUTEX_ERRORCHECK_NP`：检错锁，如果同一个线程请求同一个锁，则返回EDEADLK，否则与普通锁类型动作相同。这样就保证当不允许多次加锁时不会出现最简单情况下的死锁。
- `PTHREAD_MUTEX_ADAPTIVE_NP`：适应锁，动作最简单的锁类型，仅等待解锁后重新竞争。



**读写锁**：读写锁比mutex有更高的适用性，**可以多个线程同时占用读模式的读写锁，但是只能一个线程占用写模式的读写锁。**

- 当读写锁是**写加锁状态**时, 在这个锁被解锁之前, 所有试图对这个锁加锁的线程都会被阻塞.
- 当读写锁在**读加锁状态**时, 所有试图以读模式对它进行加锁的线程都可以得到访问权，但是以写模式对它进行枷锁的线程将阻塞； 
- 当读写锁在**读模式锁状态**时, 如果有另外线程试图以**写模式加锁**, **读写锁通常会阻塞随后的读模式锁请求**, 这样可以避免读模式锁长期占用, 而等待的写模式锁请求长期阻塞;

这种锁适用对数据结构进行读的次数比写的次数多的情况。

```C++
// 读写锁初始化
int pthread_rwlock_init(pthread_rwlock_t * rwlock,  const pthread_rwlockattr_t *  attr);
// 对读写锁加读锁
int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
// 加写锁
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
// 释放读写锁
int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
// 销毁读写锁
int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
```



**条件变量**：允许线程由于一些未达到的条件而阻塞，通常与互斥锁配合使用。条件变量的基本操作有：触发条件(当条件变为 true 时)；等待条件，挂起线程直到其他线程触发条件。

- 在等待进程中，需要等待该条件，即需要`_cond.wait()`；wait()过程将会把调用线程放到等待条件的线程列表上，然后对该互斥量解锁；此时在互斥量解锁期间，又有新的线程进入该临界区，条件尚未发生，wait()会继续这一过程。
- 在唤醒进程中，首先会进行条件检查（已经被同一个互斥量锁住，睡眠的线程不可能错过）；如果条件成立，则唤醒等待进程。
- 需要使用`while (_count > 0)`，而不是`if (_count > 0)`，原因为当线程从`_cond.wait()`唤醒时，此时互斥量会继续被锁住（此时多个线程对互斥量争用的问题），很有可能此时的条件会被其他线程修改，造成`_count > 0`的条件不成立，因此需要继续判断的。

```C++
// 条件变量的初始化与销毁
int pthread_cond_init(pthread_cond_t *restrict cond,const pthread_condattr_t *restrict attr);
int pthread_cond_destroy(pthread_cond_t *cond);
// 等待条件变量
int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);
// 唤醒等待该条件的线程
int pthread_cond_signal(pthread_cond_t * cond);
int pthread_cond_broadcast(pthread_cond_t * cond);
```



**信号量**：为控制一个具有有限数量的用户资源而设计。它允许多个线程在同一个时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。

信号量机制通过信号量的值控制可用资源的数量。线程访问共享资源前，需要申请获取一个信号量，如果信号量为0，说明当前无可用的资源，线程无法获取信号量，则该线程会等待其他资源释放信号量（信号量加1）。如果信号量不为0，说明当前有可用的资源，此时线程占用一个资源，对应信号量减1。

```C++
int sem_init(sem_t *sem, int pshared, unsigned int val);
int sem_destory(sem_t *sem);
// 该函数申请一个信号量，当前无可用信号量则等待，有可用信号量时占用一个信号量，对信号量的值减1
int sem_wait(sem_t *sem);
// 该函数释放一个信号量，信号量的值加1
int sem_post(sem_t *sem);
```



**屏障**：用户协调多个线程**并行工作**的同步机制；屏障允许每个线程等待，直到**所有的合作线程**都到达某一点（屏障），然后从该点继续执行工作。

```C++
// count用于指定在允许所有线程继续执行之前，必须到达屏障的线程数目
// 当到达了这个数目之后,线程就可以继续执行
int pthread_barrier_init(pthread_barrier_t *restrict barrier,const pthread_barrierattr_t *restrict attr,unsigned int count);
int pthread_barrier_destroy(pthread_barrier_t *barrier);
// 线程调用该函数用来表示自己已经到达了屏障
// 如果线程调用这个函数发现屏障的线程计数还未满足要求，那么线程就会进入休眠状态.
// 如果线程调用此函数之后，发现刚好满足屏障计数，那么所有的线程都被唤醒
int pthread_barrier_wait(pthread_barrier_t *barrier);
```



### 1.5 死锁





## 2. 进程间通信





## 3. C++线程标准库

